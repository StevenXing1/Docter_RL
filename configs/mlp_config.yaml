# MLP Policy Configuration
model:
  type: "mlp"
  architecture:
    hidden_sizes: [128, 128]
    activation: "relu"
    output_activation: "softmax"
  
training:
  algorithm: "reinforce"
  episodes: 1000
  max_steps: 300
  learning_rate: 0.001
  gamma: 0.99
  optimizer: "adam"
  
environment:
  name: "final_proj/RLDocter_v0"
  normalize: true
  display: false
  
logging:
  log_dir: "logs/mlp"
  tensorboard: true
  save_frequency: 100
  eval_frequency: 50
  
checkpoint:
  save_dir: "models/mlp"
  save_best: true
  save_last: true
